# @package _global_

defaults:
  - data: default
  - policy: skill_vae
  - train: default
  - eval: default
  - lifelong: multitask_pretrain
  - test: null
  - _self_

# change defaults
data:
  seq_len: 96
  obs_seq_len: 1
  use_padding: true
eval:
  eval: false
  eval_every: 50
train:
  batch_size: 1024
  num_workers: 6
  n_epochs: 100

exp_name: "codec_fq_16" # model_type: m4, seq_len: 32, fsq_levels: 4, num_kernels: 3, stride_factor: 4, encoder-decoder_causality: true-true
seed: 10000
use_wandb: false
wandb_project: "diff-skill-libero"
folder: null # use default path
bddl_folder: null # use default path
init_states_folder: null # use default path
load_previous_model: false
device: "cuda"
task_embedding_format: "clip"
task_embedding_one_hot_offset: 1
pretrain: true
pretrain_model_path: ""
benchmark_name: "LIBERO_90" # benchmark name LIBERO_10 or LIBERO_90
